Running chair_eval_llava.py
import 1/3

A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.2 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/bscho333/Decoding/eval_bench/chair_eval_llava.py", line 19, in <module>
    from llava.constants import IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN, DEFAULT_IM_START_TOKEN, DEFAULT_IM_END_TOKEN
  File "/home/bscho333/Decoding/experiments/llava/__init__.py", line 1, in <module>
    from .model import LlavaLlamaForCausalLM
  File "/home/bscho333/Decoding/experiments/llava/model/__init__.py", line 1, in <module>
    from .language_model.llava_llama import LlavaLlamaForCausalLM, LlavaConfig
  File "/home/bscho333/Decoding/experiments/llava/model/language_model/llava_llama.py", line 23, in <module>
    from transformers import AutoConfig, AutoModelForCausalLM, \
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1090, in __getattr__
    value = getattr(module, name)
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1089, in __getattr__
    module = self._get_module(self._class_to_module[name])
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1099, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 32, in <module>
    from ...modeling_utils import PreTrainedModel
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/transformers/modeling_utils.py", line 86, in <module>
    from accelerate import dispatch_model, infer_auto_device_map, init_empty_weights
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/accelerate/__init__.py", line 3, in <module>
    from .accelerator import Accelerator
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/accelerate/accelerator.py", line 35, in <module>
    from .checkpointing import load_accelerator_state, load_custom_state, save_accelerator_state, save_custom_state
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/accelerate/checkpointing.py", line 24, in <module>
    from .utils import (
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/accelerate/utils/__init__.py", line 131, in <module>
    from .bnb import has_4bit_bnb_layers, load_and_quantize_model
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/accelerate/utils/bnb.py", line 42, in <module>
    import bitsandbytes as bnb
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/bitsandbytes/__init__.py", line 6, in <module>
    from . import cuda_setup, utils, research
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/bitsandbytes/research/__init__.py", line 1, in <module>
    from . import nn
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/bitsandbytes/research/nn/__init__.py", line 1, in <module>
    from .modules import LinearFP8Mixed, LinearFP8Global
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/bitsandbytes/research/nn/modules.py", line 8, in <module>
    from bitsandbytes.optim import GlobalOptimManager
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/bitsandbytes/optim/__init__.py", line 8, in <module>
    from .adagrad import Adagrad, Adagrad8bit, Adagrad32bit
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/bitsandbytes/optim/adagrad.py", line 5, in <module>
    from bitsandbytes.optim.optimizer import Optimizer1State
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/bitsandbytes/optim/optimizer.py", line 12, in <module>
    import bitsandbytes.functional as F
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/bitsandbytes/functional.py", line 169, in <module>
    def get_paged(*shape, dtype=torch.float32, device=torch.device('cuda', index=0)):
/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/bitsandbytes/functional.py:169: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)
  def get_paged(*shape, dtype=torch.float32, device=torch.device('cuda', index=0)):
import 2/3
/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().
  warnings.warn(_BETA_TRANSFORMS_WARNING)
/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().
  warnings.warn(_BETA_TRANSFORMS_WARNING)
import 3/3
first line of chair_eval_llava.py
args.log_path:  /mnt/server16_hard0/sangmin/code/neurips2024/logs/chair
Starting rank=0, seed=42, world_size=1, device=0
Traceback (most recent call last):
  File "/home/bscho333/Decoding/eval_bench/chair_eval_llava.py", line 292, in <module>
    main()
  File "/home/bscho333/Decoding/eval_bench/chair_eval_llava.py", line 106, in main
    os.makedirs(
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  [Previous line repeated 2 more times]
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/os.py", line 225, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/mnt/server16_hard0'
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 1903558) of binary: /home/bscho333/anaconda3/envs/RITUAL/bin/python
Traceback (most recent call last):
  File "/home/bscho333/anaconda3/envs/RITUAL/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/torch/distributed/run.py", line 794, in main
    run(args)
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
eval_bench/chair_eval_llava.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-11-05_19:43:09
  host      : node01.localdomain
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 1903558)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
eval_bench/scripts/chair_eval.sh: line 39: --seed: command not found


###############################################################################################################################################
###############################################################################################################################################
###############################################################################################################################################
###############################################################################################################################################
###############################################################################################################################################

Running chair_eval_llava.py
log_path: /home/bscho333/Decoding/output/logs/chair
import 1/3

A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.2 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/bscho333/Decoding/eval_bench/chair_eval_llava.py", line 19, in <module>
    from llava.constants import IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN, DEFAULT_IM_START_TOKEN, DEFAULT_IM_END_TOKEN
  File "/home/bscho333/Decoding/experiments/llava/__init__.py", line 1, in <module>
    from .model import LlavaLlamaForCausalLM
  File "/home/bscho333/Decoding/experiments/llava/model/__init__.py", line 1, in <module>
    from .language_model.llava_llama import LlavaLlamaForCausalLM, LlavaConfig
  File "/home/bscho333/Decoding/experiments/llava/model/language_model/llava_llama.py", line 23, in <module>
    from transformers import AutoConfig, AutoModelForCausalLM, \
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1090, in __getattr__
    value = getattr(module, name)
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1089, in __getattr__
    module = self._get_module(self._class_to_module[name])
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1099, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 32, in <module>
    from ...modeling_utils import PreTrainedModel
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/transformers/modeling_utils.py", line 86, in <module>
    from accelerate import dispatch_model, infer_auto_device_map, init_empty_weights
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/accelerate/__init__.py", line 3, in <module>
    from .accelerator import Accelerator
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/accelerate/accelerator.py", line 35, in <module>
    from .checkpointing import load_accelerator_state, load_custom_state, save_accelerator_state, save_custom_state
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/accelerate/checkpointing.py", line 24, in <module>
    from .utils import (
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/accelerate/utils/__init__.py", line 131, in <module>
    from .bnb import has_4bit_bnb_layers, load_and_quantize_model
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/accelerate/utils/bnb.py", line 42, in <module>
    import bitsandbytes as bnb
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/bitsandbytes/__init__.py", line 6, in <module>
    from . import cuda_setup, utils, research
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/bitsandbytes/research/__init__.py", line 1, in <module>
    from . import nn
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/bitsandbytes/research/nn/__init__.py", line 1, in <module>
    from .modules import LinearFP8Mixed, LinearFP8Global
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/bitsandbytes/research/nn/modules.py", line 8, in <module>
    from bitsandbytes.optim import GlobalOptimManager
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/bitsandbytes/optim/__init__.py", line 8, in <module>
    from .adagrad import Adagrad, Adagrad8bit, Adagrad32bit
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/bitsandbytes/optim/adagrad.py", line 5, in <module>
    from bitsandbytes.optim.optimizer import Optimizer1State
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/bitsandbytes/optim/optimizer.py", line 12, in <module>
    import bitsandbytes.functional as F
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/bitsandbytes/functional.py", line 169, in <module>
    def get_paged(*shape, dtype=torch.float32, device=torch.device('cuda', index=0)):
/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/bitsandbytes/functional.py:169: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)
  def get_paged(*shape, dtype=torch.float32, device=torch.device('cuda', index=0)):
import 2/3
/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().
  warnings.warn(_BETA_TRANSFORMS_WARNING)
/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().
  warnings.warn(_BETA_TRANSFORMS_WARNING)
import 3/3
first line of chair_eval_llava.py
args:  Namespace(model_path=None, model_base='llava', conv_mode='llava_v1', temperature=1.0, top_p=1, top_k=None, data_path='/mnt/server17_hard1/sangmin/data/coco/val2014/', anno_path='/mnt/server17_hard1/sangmin/data/coco/annotations/instances_val2014.json', log_path='/mnt/server16_hard0/sangmin/code/neurips2024/logs/chair', out_path='/mnt/server16_hard0/sangmin/code/neurips2024/chair_results/llava', seed=42, batch_size=1, num_workers=2, use_ritual=False, use_vcd=False, noise_step=500, use_m3id=False, ritual_alpha_pos=3, ritual_alpha_neg=1, ritual_beta=0.1, num_eval_samples=500, max_new_tokens=64, experiment_index=0)
args.log_path:  /mnt/server16_hard0/sangmin/code/neurips2024/logs/chair
Starting rank=0, seed=42, world_size=1, device=0
Traceback (most recent call last):
  File "/home/bscho333/Decoding/eval_bench/chair_eval_llava.py", line 293, in <module>
    main()
  File "/home/bscho333/Decoding/eval_bench/chair_eval_llava.py", line 107, in main
    os.makedirs(
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  [Previous line repeated 2 more times]
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/os.py", line 225, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/mnt/server16_hard0'
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 1903700) of binary: /home/bscho333/anaconda3/envs/RITUAL/bin/python
Traceback (most recent call last):
  File "/home/bscho333/anaconda3/envs/RITUAL/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/torch/distributed/run.py", line 794, in main
    run(args)
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
eval_bench/chair_eval_llava.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-11-05_19:47:53
  host      : node01.localdomain
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 1903700)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
eval_bench/scripts/chair_eval.sh: line 40: l_base: command not found


###############################################################################################################################################
###############################################################################################################################################
###############################################################################################################################################
###############################################################################################################################################
###############################################################################################################################################

Running chair_eval_llava.py
log_path: /home/bscho333/Decoding/output/logs/chair
import 1/3

A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.2 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/bscho333/Decoding/eval_bench/chair_eval_llava.py", line 19, in <module>
    from llava.constants import IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN, DEFAULT_IM_START_TOKEN, DEFAULT_IM_END_TOKEN
  File "/home/bscho333/Decoding/experiments/llava/__init__.py", line 1, in <module>
    from .model import LlavaLlamaForCausalLM
  File "/home/bscho333/Decoding/experiments/llava/model/__init__.py", line 1, in <module>
    from .language_model.llava_llama import LlavaLlamaForCausalLM, LlavaConfig
  File "/home/bscho333/Decoding/experiments/llava/model/language_model/llava_llama.py", line 23, in <module>
    from transformers import AutoConfig, AutoModelForCausalLM, \
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1090, in __getattr__
    value = getattr(module, name)
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1089, in __getattr__
    module = self._get_module(self._class_to_module[name])
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1099, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 32, in <module>
    from ...modeling_utils import PreTrainedModel
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/transformers/modeling_utils.py", line 86, in <module>
    from accelerate import dispatch_model, infer_auto_device_map, init_empty_weights
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/accelerate/__init__.py", line 3, in <module>
    from .accelerator import Accelerator
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/accelerate/accelerator.py", line 35, in <module>
    from .checkpointing import load_accelerator_state, load_custom_state, save_accelerator_state, save_custom_state
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/accelerate/checkpointing.py", line 24, in <module>
    from .utils import (
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/accelerate/utils/__init__.py", line 131, in <module>
    from .bnb import has_4bit_bnb_layers, load_and_quantize_model
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/accelerate/utils/bnb.py", line 42, in <module>
    import bitsandbytes as bnb
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/bitsandbytes/__init__.py", line 6, in <module>
    from . import cuda_setup, utils, research
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/bitsandbytes/research/__init__.py", line 1, in <module>
    from . import nn
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/bitsandbytes/research/nn/__init__.py", line 1, in <module>
    from .modules import LinearFP8Mixed, LinearFP8Global
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/bitsandbytes/research/nn/modules.py", line 8, in <module>
    from bitsandbytes.optim import GlobalOptimManager
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/bitsandbytes/optim/__init__.py", line 8, in <module>
    from .adagrad import Adagrad, Adagrad8bit, Adagrad32bit
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/bitsandbytes/optim/adagrad.py", line 5, in <module>
    from bitsandbytes.optim.optimizer import Optimizer1State
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/bitsandbytes/optim/optimizer.py", line 12, in <module>
    import bitsandbytes.functional as F
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/bitsandbytes/functional.py", line 169, in <module>
    def get_paged(*shape, dtype=torch.float32, device=torch.device('cuda', index=0)):
/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/bitsandbytes/functional.py:169: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)
  def get_paged(*shape, dtype=torch.float32, device=torch.device('cuda', index=0)):
import 2/3
/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().
  warnings.warn(_BETA_TRANSFORMS_WARNING)
/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().
  warnings.warn(_BETA_TRANSFORMS_WARNING)
import 3/3
first line of chair_eval_llava.py
args:  Namespace(model_path='/home/bscho333/data/llava-v1.5-7b', model_base='llava', conv_mode='llava_v1', temperature=1.0, top_p=1, top_k=None, data_path='/home/bscho333/data/coco/val2014/', anno_path='/home/bscho333/data/coco/annotations/instances_val2014.json', log_path='/home/bscho333/Decoding/output/logs/chair', out_path='/home/bscho333/Decoding/output/chair_results', seed=42, batch_size=1, num_workers=2, use_ritual=False, use_vcd=False, noise_step=500, use_m3id=False, ritual_alpha_pos=3.0, ritual_alpha_neg=1.0, ritual_beta=0.1, num_eval_samples=500, max_new_tokens=64, experiment_index=0)
args.log_path:  /home/bscho333/Decoding/output/logs/chair
Starting rank=0, seed=42, world_size=1, device=0
[2024-11-05 19:50:13] Experiment directory created at /home/bscho333/Decoding/output/logs/chair/llava-v1.5-7b/0
[2024-11-05 19:50:13] Initializing Model
Initializing Model
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:42<00:42, 42.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:59<00:00, 27.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:59<00:00, 29.93s/it]
Error while downloading from https://cdn-lfs.hf.co/repos/aa/ef/aaef666503e18a889e4a927d9595921c7011b713a81cf619fbc411be6f69e9d6/c6032c2e0caae3dc2d4fba35535fa6307dbb49df59c7e182b1bc4b3329b81801?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1731061983&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMTA2MTk4M319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy9hYS9lZi9hYWVmNjY2NTAzZTE4YTg4OWU0YTkyN2Q5NTk1OTIxYzcwMTFiNzEzYTgxY2Y2MTlmYmM0MTFiZTZmNjllOWQ2L2M2MDMyYzJlMGNhYWUzZGMyZDRmYmEzNTUzNWZhNjMwN2RiYjQ5ZGY1OWM3ZTE4MmIxYmM0YjMzMjliODE4MDE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=hWu-Xey-PvR6jPA1Op15wbmb9lOhZriRr0N3YssZhcW1G4ARx1PAmBL1iNVRpUKrRwSha-vlcSM9r2kjNweIZuxTQKHETxtFHAspyP998vVW5ltfYptvKcqJMRog%7EmBgz70kJcGnVxi296OwbJneoqMT3xJNXSQ4YjWPQbBg%7EQ9GZvWKZsVsqG-mJ5fRE%7E5WHVUZAgSVM%7EztMQW--RbfDyvn2OMSct%7EjxuC0hgXjfZ6%7E1eaO23eM61b1xua98PBi9oiybPkPAtSGG9UxOx%7EwV8lAjZRvKl-f%7E-FHfXDXC87CBhGM0DssXzn1RxVZz7VGFrmDdHziUrnLMzDJgNXpTg__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.
Trying to resume download...
[2024-11-05 21:58:26] Error while downloading from https://cdn-lfs.hf.co/repos/aa/ef/aaef666503e18a889e4a927d9595921c7011b713a81cf619fbc411be6f69e9d6/c6032c2e0caae3dc2d4fba35535fa6307dbb49df59c7e182b1bc4b3329b81801?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1731061983&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMTA2MTk4M319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy9hYS9lZi9hYWVmNjY2NTAzZTE4YTg4OWU0YTkyN2Q5NTk1OTIxYzcwMTFiNzEzYTgxY2Y2MTlmYmM0MTFiZTZmNjllOWQ2L2M2MDMyYzJlMGNhYWUzZGMyZDRmYmEzNTUzNWZhNjMwN2RiYjQ5ZGY1OWM3ZTE4MmIxYmM0YjMzMjliODE4MDE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=hWu-Xey-PvR6jPA1Op15wbmb9lOhZriRr0N3YssZhcW1G4ARx1PAmBL1iNVRpUKrRwSha-vlcSM9r2kjNweIZuxTQKHETxtFHAspyP998vVW5ltfYptvKcqJMRog%7EmBgz70kJcGnVxi296OwbJneoqMT3xJNXSQ4YjWPQbBg%7EQ9GZvWKZsVsqG-mJ5fRE%7E5WHVUZAgSVM%7EztMQW--RbfDyvn2OMSct%7EjxuC0hgXjfZ6%7E1eaO23eM61b1xua98PBi9oiybPkPAtSGG9UxOx%7EwV8lAjZRvKl-f%7E-FHfXDXC87CBhGM0DssXzn1RxVZz7VGFrmDdHziUrnLMzDJgNXpTg__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.
Trying to resume download...
Model loaded
Dataset loaded
[2024-11-05 22:05:36] Start eval...
Start eval...
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 0/500 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "/home/bscho333/Decoding/eval_bench/chair_eval_llava.py", line 293, in <module>
    main()
  File "/home/bscho333/Decoding/eval_bench/chair_eval_llava.py", line 173, in main
    for batch_id, data in tqdm(enumerate(chair_loader), total=args.num_eval_samples):
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/tqdm/std.py", line 1181, in __iter__
    for obj in iterable:
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1345, in _next_data
    return self._process_data(data)
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1371, in _process_data
    data.reraise()
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/torch/_utils.py", line 644, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/transformers/feature_extraction_utils.py", line 175, in convert_to_tensors
    tensor = as_tensor(value)
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/transformers/feature_extraction_utils.py", line 149, in as_tensor
    return torch.tensor(value)
RuntimeError: Could not infer dtype of numpy.float32

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/bscho333/Decoding/eval_bench/chair_loader.py", line 50, in __getitem__
    image_tensor = self.trans.preprocess(raw_image, return_tensors='pt')['pixel_values'][0]
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/transformers/models/clip/image_processing_clip.py", line 337, in preprocess
    return BatchFeature(data=data, tensor_type=return_tensors)
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/transformers/feature_extraction_utils.py", line 78, in __init__
    self.convert_to_tensors(tensor_type=tensor_type)
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/transformers/feature_extraction_utils.py", line 181, in convert_to_tensors
    raise ValueError(
ValueError: Unable to create tensor, you should probably activate padding with 'padding=True' to have batched tensors with the same length.

ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 1903763) of binary: /home/bscho333/anaconda3/envs/RITUAL/bin/python
Traceback (most recent call last):
  File "/home/bscho333/anaconda3/envs/RITUAL/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/torch/distributed/run.py", line 794, in main
    run(args)
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/bscho333/anaconda3/envs/RITUAL/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
eval_bench/chair_eval_llava.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-11-05_22:05:41
  host      : node01.localdomain
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 1903763)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
