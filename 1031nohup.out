#################
#CBS: chair_eval.sh
#################

Running chair_eval_llava.py

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please run

python -m bitsandbytes

 and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
bin /home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda113.so
/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/home/bscho333/anaconda3/envs/trsfm_4_31/lib/libcudart.so.11.0'), PosixPath('/home/bscho333/anaconda3/envs/trsfm_4_31/lib/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.
Either way, this might cause trouble in the future:
If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.
  warn(msg)
CUDA SETUP: CUDA runtime path found: /home/bscho333/anaconda3/envs/trsfm_4_31/lib/libcudart.so.11.0
CUDA SETUP: Highest compute capability among GPUs detected: 8.6
CUDA SETUP: Detected CUDA version 113
CUDA SETUP: Loading binary /home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...
Traceback (most recent call last):
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/transformers/utils/import_utils.py", line 1099, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 32, in <module>
    from ...modeling_utils import PreTrainedModel
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/transformers/modeling_utils.py", line 86, in <module>
    from accelerate import dispatch_model, infer_auto_device_map, init_empty_weights
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/accelerate/__init__.py", line 3, in <module>
    from .accelerator import Accelerator
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/accelerate/accelerator.py", line 35, in <module>
    from .checkpointing import load_accelerator_state, load_custom_state, save_accelerator_state, save_custom_state
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/accelerate/checkpointing.py", line 24, in <module>
    from .utils import (
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/accelerate/utils/__init__.py", line 132, in <module>
    from .fsdp_utils import load_fsdp_model, load_fsdp_optimizer, save_fsdp_model, save_fsdp_optimizer
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/accelerate/utils/fsdp_utils.py", line 24, in <module>
    import torch.distributed.checkpoint as dist_cp
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/torch/distributed/checkpoint/__init__.py", line 7, in <module>
    from .state_dict_loader import load_state_dict
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/torch/distributed/checkpoint/state_dict_loader.py", line 9, in <module>
    from .default_planner import DefaultLoadPlanner
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/torch/distributed/checkpoint/default_planner.py", line 13, in <module>
    from torch.distributed._shard._utils import narrow_tensor_by_index
ImportError: cannot import name 'narrow_tensor_by_index' from 'torch.distributed._shard._utils' (/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/torch/distributed/_shard/_utils.py)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/bscho333/Decoding/eval_bench/chair_eval_llava.py", line 18, in <module>
    from llava.constants import IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN, DEFAULT_IM_START_TOKEN, DEFAULT_IM_END_TOKEN
  File "/home/bscho333/Decoding/experiments/llava/__init__.py", line 1, in <module>
    from .model import LlavaLlamaForCausalLM
  File "/home/bscho333/Decoding/experiments/llava/model/__init__.py", line 1, in <module>
    from .language_model.llava_llama import LlavaLlamaForCausalLM, LlavaConfig
  File "/home/bscho333/Decoding/experiments/llava/model/language_model/llava_llama.py", line 23, in <module>
    from transformers import AutoConfig, AutoModelForCausalLM, \
  File "<frozen importlib._bootstrap>", line 1055, in _handle_fromlist
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/transformers/utils/import_utils.py", line 1090, in __getattr__
    value = getattr(module, name)
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/transformers/utils/import_utils.py", line 1089, in __getattr__
    module = self._get_module(self._class_to_module[name])
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/transformers/utils/import_utils.py", line 1101, in _get_module
    raise RuntimeError(
RuntimeError: Failed to import transformers.models.llama.modeling_llama because of the following error (look up to see its traceback):
cannot import name 'narrow_tensor_by_index' from 'torch.distributed._shard._utils' (/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/torch/distributed/_shard/_utils.py)
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 4040084) of binary: /home/bscho333/anaconda3/envs/trsfm_4_31/bin/python
Traceback (most recent call last):
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==1.12.1', 'console_scripts', 'torchrun')())
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/torch/distributed/run.py", line 761, in main
    run(args)
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/torch/distributed/run.py", line 752, in run
    elastic_launch(
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
eval_bench/chair_eval_llava.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-10-31_19:44:34
  host      : node15.localdomain
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 4040084)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
eval_bench/scripts/chair_eval.sh: line 39: --seed: command not found



#################
#CBS: chair_eval_single.sh
#################

Running chair_eval_llava.py
/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/home/bscho333/anaconda3/envs/trsfm_4_31/lib/libcudart.so'), PosixPath('/home/bscho333/anaconda3/envs/trsfm_4_31/lib/libcudart.so.11.0')}.. We'll flip a coin and try one of these, in order to fail forward.
Either way, this might cause trouble in the future:
If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.
  warn(msg)

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please run

python -m bitsandbytes

 and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
bin /home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda113.so
CUDA SETUP: CUDA runtime path found: /home/bscho333/anaconda3/envs/trsfm_4_31/lib/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.6
CUDA SETUP: Detected CUDA version 113
CUDA SETUP: Loading binary /home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...
Traceback (most recent call last):
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/transformers/utils/import_utils.py", line 1099, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 32, in <module>
    from ...modeling_utils import PreTrainedModel
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/transformers/modeling_utils.py", line 86, in <module>
    from accelerate import dispatch_model, infer_auto_device_map, init_empty_weights
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/accelerate/__init__.py", line 3, in <module>
    from .accelerator import Accelerator
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/accelerate/accelerator.py", line 35, in <module>
    from .checkpointing import load_accelerator_state, load_custom_state, save_accelerator_state, save_custom_state
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/accelerate/checkpointing.py", line 24, in <module>
    from .utils import (
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/accelerate/utils/__init__.py", line 132, in <module>
    from .fsdp_utils import load_fsdp_model, load_fsdp_optimizer, save_fsdp_model, save_fsdp_optimizer
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/accelerate/utils/fsdp_utils.py", line 24, in <module>
    import torch.distributed.checkpoint as dist_cp
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/torch/distributed/checkpoint/__init__.py", line 7, in <module>
    from .state_dict_loader import load_state_dict
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/torch/distributed/checkpoint/state_dict_loader.py", line 9, in <module>
    from .default_planner import DefaultLoadPlanner
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/torch/distributed/checkpoint/default_planner.py", line 13, in <module>
    from torch.distributed._shard._utils import narrow_tensor_by_index
ImportError: cannot import name 'narrow_tensor_by_index' from 'torch.distributed._shard._utils' (/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/torch/distributed/_shard/_utils.py)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/bscho333/Decoding/eval_bench/chair_eval_llava_single.py", line 18, in <module>
    from llava.constants import IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN, DEFAULT_IM_START_TOKEN, DEFAULT_IM_END_TOKEN
  File "/home/bscho333/Decoding/experiments/llava/__init__.py", line 1, in <module>
    from .model import LlavaLlamaForCausalLM
  File "/home/bscho333/Decoding/experiments/llava/model/__init__.py", line 1, in <module>
    from .language_model.llava_llama import LlavaLlamaForCausalLM, LlavaConfig
  File "/home/bscho333/Decoding/experiments/llava/model/language_model/llava_llama.py", line 23, in <module>
    from transformers import AutoConfig, AutoModelForCausalLM, \
  File "<frozen importlib._bootstrap>", line 1055, in _handle_fromlist
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/transformers/utils/import_utils.py", line 1090, in __getattr__
    value = getattr(module, name)
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/transformers/utils/import_utils.py", line 1089, in __getattr__
    module = self._get_module(self._class_to_module[name])
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/transformers/utils/import_utils.py", line 1101, in _get_module
    raise RuntimeError(
RuntimeError: Failed to import transformers.models.llama.modeling_llama because of the following error (look up to see its traceback):
cannot import name 'narrow_tensor_by_index' from 'torch.distributed._shard._utils' (/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/torch/distributed/_shard/_utils.py)
