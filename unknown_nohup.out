#################
#CBS: 몰루..
#################

Running chair_eval_llava.py
False

===================================BUG REPORT===================================
/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:166: UserWarning: Welcome to bitsandbytes. For bug reports, please run

python -m bitsandbytes


  warn(msg)
================================================================================
/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:166: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/home/bscho333/anaconda3/envs/trsfm_4_31/lib/libcudart.so.11.0'), PosixPath('/home/bscho333/anaconda3/envs/trsfm_4_31/lib/libcudart.so')}.. We select the PyTorch default libcudart.so, which is {torch.version.cuda},but this might missmatch with the CUDA version that is needed for bitsandbytes.To override this behavior set the BNB_CUDA_VERSION=<version string, e.g. 122> environmental variableFor example, if you want to use the CUDA version 122BNB_CUDA_VERSION=122 python ...OR set the environmental variable in your .bashrc: export BNB_CUDA_VERSION=122In the case of a manual override, make sure you set the LD_LIBRARY_PATH, e.g.export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-11.2
  warn(msg)
/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:166: UserWarning: /home/bscho333/anaconda3/envs/trsfm_4_31 did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...
  warn(msg)
/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:166: UserWarning: /opt/ohpc/pub/apps/cuda/12.5/lib64 did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...
  warn(msg)
The following directories listed in your path were found to be non-existent: {PosixPath('1')}
The following directories listed in your path were found to be non-existent: {PosixPath('/usr/share/man/overrides'), PosixPath('/opt/ohpc/pub/apps/cuda/12.5/doc'), PosixPath('/usr/share/man/en')}
The following directories listed in your path were found to be non-existent: {PosixPath('1')}
The following directories listed in your path were found to be non-existent: {PosixPath('1;/opt/ohpc/pub/bin'), PosixPath('1;/usr/local/sbin'), PosixPath('1;/home/bscho333/.vscode-server/cli/servers/Stable-384ff7382de624fb94dbaf6da11977bba1ecd427/server/bin/remote-cli'), PosixPath('1;/home/bscho333/bin'), PosixPath('1;/usr/local/bin'), PosixPath('1;/opt/ohpc/pub/apps/cuda/12.5/bin'), PosixPath('1;/usr/bin'), PosixPath('1'), PosixPath('1;/home/bscho333/anaconda3/condabin'), PosixPath('1;/usr/sbin'), PosixPath('1;/home/bscho333/.local/bin'), PosixPath('1;/home/bscho333/anaconda3/bin')}
The following directories listed in your path were found to be non-existent: {PosixPath('1')}
The following directories listed in your path were found to be non-existent: {PosixPath('/run/user/10408/vscode-git-05c3d02dea.sock')}
The following directories listed in your path were found to be non-existent: {PosixPath('ohpc'), PosixPath('java/22.0.2'), PosixPath('cuda/12.5')}
The following directories listed in your path were found to be non-existent: {PosixPath('4'), PosixPath('4;/usr/share/man'), PosixPath('4;/usr/share/man/overrides'), PosixPath('/opt/ohpc/pub/apps/cuda/12.5/doc'), PosixPath('1;/usr/local/share/man'), PosixPath('4;/usr/share/man/en')}
The following directories listed in your path were found to be non-existent: {PosixPath('https'), PosixPath('//debuginfod.centos.org/ ')}
The following directories listed in your path were found to be non-existent: {PosixPath('1')}
The following directories listed in your path were found to be non-existent: {PosixPath('/run/user/10408/vscode-ipc-ff039a75-3b4f-48b7-baff-e1c8da3f2eb4.sock')}
The following directories listed in your path were found to be non-existent: {PosixPath('() {  eval "$($LMOD_DIR/ml_cmd "$@")"\n}')}
The following directories listed in your path were found to be non-existent: {PosixPath('() {  ( alias;\n eval ${which_declare} ) | /usr/bin/which --tty-only --read-alias --read-functions --show-tilde --show-dot $@\n}')}
The following directories listed in your path were found to be non-existent: {PosixPath('/tmp/torchelastic_1cn7aqdb/none_kgcrxogg/attempt_0/0/error.json')}
DEBUG: Possible options found for libcudart.so: {PosixPath('/opt/ohpc/pub/apps/cuda/12.5/lib64/libcudart.so')}
CUDA SETUP: PyTorch settings found: CUDA_VERSION=113, Highest Compute Capability: 8.6.
CUDA SETUP: To manually override the PyTorch CUDA version please see:https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md
CUDA SETUP: Required library version not found: libbitsandbytes_cuda113.so. Maybe you need to compile it from source?
CUDA SETUP: Defaulting to libbitsandbytes_cpu.so...

================================================ERROR=====================================
CUDA SETUP: CUDA detection failed! Possible reasons:
1. You need to manually override the PyTorch CUDA version. Please see: "https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md
2. CUDA driver not installed
3. CUDA not installed
4. You have multiple conflicting CUDA libraries
5. Required library not pre-compiled for this bitsandbytes release!
CUDA SETUP: If you compiled from source, try again with `make CUDA_VERSION=DETECTED_CUDA_VERSION` for example, `make CUDA_VERSION=113`.
CUDA SETUP: The CUDA version for the compile might depend on your conda install. Inspect CUDA version via `conda list | grep cuda`.
================================================================================

CUDA SETUP: Something unexpected happened. Please compile from source:
git clone https://github.com/TimDettmers/bitsandbytes.git
cd bitsandbytes
CUDA_VERSION=113 make cuda11x
python setup.py install
CUDA SETUP: Setup Failed!
Traceback (most recent call last):
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/transformers/utils/import_utils.py", line 1099, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 32, in <module>
    from ...modeling_utils import PreTrainedModel
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/transformers/modeling_utils.py", line 86, in <module>
    from accelerate import dispatch_model, infer_auto_device_map, init_empty_weights
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/accelerate/__init__.py", line 3, in <module>
    from .accelerator import Accelerator
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/accelerate/accelerator.py", line 35, in <module>
    from .checkpointing import load_accelerator_state, load_custom_state, save_accelerator_state, save_custom_state
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/accelerate/checkpointing.py", line 24, in <module>
    from .utils import (
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/accelerate/utils/__init__.py", line 131, in <module>
    from .bnb import has_4bit_bnb_layers, load_and_quantize_model
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/accelerate/utils/bnb.py", line 42, in <module>
    import bitsandbytes as bnb
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/bitsandbytes/__init__.py", line 6, in <module>
    from . import cuda_setup, utils, research
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/bitsandbytes/research/__init__.py", line 1, in <module>
    from . import nn
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/bitsandbytes/research/nn/__init__.py", line 1, in <module>
    from .modules import LinearFP8Mixed, LinearFP8Global
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/bitsandbytes/research/nn/modules.py", line 8, in <module>
    from bitsandbytes.optim import GlobalOptimManager
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/bitsandbytes/optim/__init__.py", line 6, in <module>
    from bitsandbytes.cextension import COMPILED_WITH_CUDA
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/bitsandbytes/cextension.py", line 20, in <module>
    raise RuntimeError('''
RuntimeError: 
        CUDA Setup failed despite GPU being available. Please run the following command to get more information:

        python -m bitsandbytes

        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them
        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes
        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/bscho333/Decoding/eval_bench/chair_eval_llava.py", line 18, in <module>
    from llava.constants import IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN, DEFAULT_IM_START_TOKEN, DEFAULT_IM_END_TOKEN
  File "/home/bscho333/Decoding/experiments/llava/__init__.py", line 1, in <module>
    from .model import LlavaLlamaForCausalLM
  File "/home/bscho333/Decoding/experiments/llava/model/__init__.py", line 1, in <module>
    from .language_model.llava_llama import LlavaLlamaForCausalLM, LlavaConfig
  File "/home/bscho333/Decoding/experiments/llava/model/language_model/llava_llama.py", line 23, in <module>
    from transformers import AutoConfig, AutoModelForCausalLM, \
  File "<frozen importlib._bootstrap>", line 1055, in _handle_fromlist
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/transformers/utils/import_utils.py", line 1090, in __getattr__
    value = getattr(module, name)
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/transformers/utils/import_utils.py", line 1089, in __getattr__
    module = self._get_module(self._class_to_module[name])
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/transformers/utils/import_utils.py", line 1101, in _get_module
    raise RuntimeError(
RuntimeError: Failed to import transformers.models.llama.modeling_llama because of the following error (look up to see its traceback):

        CUDA Setup failed despite GPU being available. Please run the following command to get more information:

        python -m bitsandbytes

        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them
        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes
        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 4155367) of binary: /home/bscho333/anaconda3/envs/trsfm_4_31/bin/python
Traceback (most recent call last):
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==1.12.1', 'console_scripts', 'torchrun')())
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/torch/distributed/run.py", line 761, in main
    run(args)
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/torch/distributed/run.py", line 752, in run
    elastic_launch(
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/bscho333/anaconda3/envs/trsfm_4_31/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
eval_bench/chair_eval_llava.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-11-01_18:11:03
  host      : node15.localdomain
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 4155367)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
eval_bench/scripts/chair_eval.sh: line 39: --seed: command not found
